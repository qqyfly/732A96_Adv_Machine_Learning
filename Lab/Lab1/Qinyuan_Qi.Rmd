---
title: "732A96 - Advanced Machine Learning - Lab 1"
author: 
  - Qinyuan Qi(qinqi464)
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE, echo=FALSE}
###########################  Init code For Assignment ##########################
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
library(bnlearn)
library(gRain)
```

# Exercises 1

Show that multiple runs of the hill-climbing algorithm can return non-equivalent Bayesian
network (BN) structures. Explain why this happens. Use the Asia dataset which is in-
cluded in the bnlearn package. To load the data, run data("asia"). Recall from
the lectures that the concept of non-equivalent BN structures has a precise meaning.

Hint: Check the function hc in the bnlearn package. Note that you can specify
the initial structure, the number of random restarts, the score, and the equivalent sam-
ple size (a.k.a imaginary sample size) in the BDeu score. You may want to use these
options to answer the question. You may also want to use the functions plot, arcs,
vstructs, cpdag and all.equal

## Answer:

According to the question, we will change the score, start, restart and iss number to see the difference between the two hill climbing algorithms.
Also we will compare the output of cpdag and vstructs to see difference of the hill climbing algorithms with different parameters.

### 1.1  default parameters vs restart = 10
We call hc function with the default parameters(score=bic,restart=0), and then change restart to 10, after that we verify the equivalence between the two hill climbing algorithms 1 and 2.

```{r q1_1}
###########################  Code For Exercises 1.1 ############################
# default parameters vs restart = 10

# Parameters
# 1. score:default:bic
#    1). bic:the Bayesian Information Criterion (BIC) score
#    2). bde:the logarithm of the Bayesian Dirichlet equivalent (uniform) score (BDeu)
# 2. restart:the number of random restarts(integer), default: 0
# 3. iss:the imaginary sample size used by the Bayesian Dirichlet scores 
#   (bde, mbde, bds, bdj),default: 1
# 4. start:the initial structure of the network, default: empty graph(NULL)
data("asia")
hill_climbing_1 <- hc(asia)
hill_climbing_2 <- hc(asia, restart = 10)
# calc the score of the two hill climbing algorithms
cat("The score of hill climbing algorithm 1 and 2 are:", score(hill_climbing_1, asia), 
    "and" ,score(hill_climbing_2, asia))
# check equivalent using all.equal
cat("Equivalency between two hill climbing algorithms:", 
    all.equal(hill_climbing_1, hill_climbing_2))
```

```{r q1_1_plot,fig.height=2,fig.cap="The difference between hill climbing algorithms 1 and 3",echo=FALSE,message = FALSE}
# plot the graph
par(mfrow = c(1, 2))
graphviz.compare(hill_climbing_1, hill_climbing_2)
```

### 1.2 default parameters vs initial structure(random)
Then we specify the initial structure, and then check the equivalence between the two hill climbing algorithms 1 and 3.

```{r q1_2}
###########################  Code For Exercises 1.2 ############################
# default parameters vs initial structure(random)

initial_structure <- random.graph(names(asia), num = 1, method = "ordered")
hill_climbing_3 <- hc(asia, start = initial_structure)
# calc the score of the two hill climbing algorithms
cat("The score of hill climbing algorithm 1 and 3 are:", score(hill_climbing_1, asia), 
    "and" ,score(hill_climbing_3, asia))
# check equivalent using all.equal
cat("Equivalency between two hill climbing algorithms:", 
    all.equal(hill_climbing_1, hill_climbing_3))
```

```{r q1_2_plot,fig.height=2,fig.cap="The difference between hill climbing algorithms 1 and 3",echo=FALSE,message = FALSE}
# plot the graph
par(mfrow = c(1, 2))
graphviz.compare(hill_climbing_1, hill_climbing_3)
```

### 1.3 [restart = 100, BIC] vs [restart = 100, BDE]
Then we change the score to bde, and set restart to 100, verify the equivalence between the two hill climbing algorithms 2 and 4.

```{r q1_3}
###########################  Code For Exercises 1.3 ############################
# [restart = 100, BIC] vs [restart = 100, BDE]

# change score value
hill_climbing_4 <- hc(asia,score = "bde", restart = 100)
# calc the score of the two hill climbing algorithms
cat("The score of hill climbing algorithm 2 and 4 are:", score(hill_climbing_2, asia), 
    "and" ,score(hill_climbing_4, asia))
# check equivalent using all.equal
cat("Equivalency between two hill climbing algorithms:", 
    all.equal(hill_climbing_2, hill_climbing_4))
```

```{r q1_3_plot,fig.height=2,fig.cap="The difference between hill climbing algorithms 2 and 4",echo=FALSE,message = FALSE}
# plot the graph
par(mfrow = c(1, 2))
graphviz.compare(hill_climbing_2, hill_climbing_4)
```

### 1.4 [BDE, restart = 100, ISS=1(default)] vs [BDE, restart = 100, iss = 100]

Then we copy all the parameter of hill_climbing_4 and change iss to 100.

```{r q1_4}
###########################  Code For Exercises 1.4 ############################
# [BDE, restart = 100, ISS=1(default)] vs [BDE, restart = 100, iss = 100]

# change iss value
hill_climbing_5 <- hc(asia,score = "bde", restart = 100, iss = 100)
# calc the score of the two hill climbing algorithms
cat("The score of hill climbing algorithm 4 and 5 are:", score(hill_climbing_4, asia), 
    "and" ,score(hill_climbing_5, asia))
# check equivalent using all.equal
cat("Equivalency between two hill climbing algorithms:", 
    all.equal(hill_climbing_4, hill_climbing_5))
```

```{r q1_4_plot,fig.height=2,fig.cap="The difference between hill climbing algorithms 4 and 5",echo=FALSE,message = FALSE}
# plot the graph
par(mfrow = c(1, 2))
graphviz.compare(hill_climbing_4, hill_climbing_5)
```

### 1.5 output of cpdag and vstructs


We also check the cpdag output of all hill climbing algorithms,listed below.

```{r q1_5_1, echo=FALSE}
###########################  Code For Exercises 1.5 ############################
# output of cpdag 

cpdag(hill_climbing_1)
cpdag(hill_climbing_2)
cpdag(hill_climbing_3)
cpdag(hill_climbing_4)
cpdag(hill_climbing_5)
```

And vstructs output of all hill climbing algorithms,listed below.
```{r q1_5_2, echo=FALSE}
# output of vstructs 
vstructs(hill_climbing_1)
vstructs(hill_climbing_2)
vstructs(hill_climbing_3)
vstructs(hill_climbing_4)
vstructs(hill_climbing_5)
```

### 1.6 comment

We found that when we run the same code it will generate several different results even if we just recompile the Rmd file. (Different arc sets/number of directed/undirected arcs/ True). For those HL algorithms with the same score, same vstructs, all.equal=TRUE, their cpdag's [tests used in the learning procedure] still can be different. 

We also found that when we increase the restart value from 1 to 100, the result does not change significantly, maybe just because the model is relatively simple. Since restart will help the model jump out of the local optimal, we will use a relatively big number to help the model find the global optimal.(we set 100 here).

And for iss, if we increase the value to a big number, say 100, we can find the model gets very complicated. And [tests used in the learning procedure] in cpdag's output get much bigger than others, it need more data or steps to train or to optimize the score and this makes sense.

Regarding the equivalent of two BN, they need to meet 2 conditions:

1) They have the same unshielded colliders
2) They have the same adjacencies

When we call the hill climbing algorithm, it will run from an empty DAG, and then add/remove/reverse edges to improve the score. But the hill climbing algorithm is a local search algorithm, it can not guarantee to find the global optimal solution. So if the algorithm is stuck in a local optimal, even when we set a restart value to help it jump out of the trap, it still can not guarantee to find the same optimal(or global optimal) result every time.

# Exercises 2

Learn a BN from 80 % of the Asia dataset. The dataset is included in the bnlearn
package. To load the data, run data("asia"). Learn both the structure and the
parameters. Use any learning algorithm and settings that you consider appropriate.
Use the BN learned to classify the remaining 20 % of the Asia dataset in two classes:
S = yes and S = no. In other words, compute the posterior probability distribution of S
for each case and classify it in the most likely class. To do so, you have to use exact
or approximate inference with the help of the bnlearn and gRain packages, i.e. you
are not allowed to use functions such as predict. Report the confusion matrix, i.e.
true/false positives/negatives. Compare your results with those of the true Asia BN,
which can be obtained by running

dag = model2network("[A][S][T|A][L|S][B|S][D|B:E][E|T:L][X|E]").

Hint: You already know two algorithms for exact inference in BNs: Variable elimi-
nation and cluster trees. There are also approximate algorithms for when the exact
ones are too demanding computationally. For exact inference, you may need the func-
tions bn.fit and as.grain from the bnlearn package, and the functions compile,
setEvidence and querygrain from the package gRain. For approximate infer-
ence, you may need the functions cpquery or cpdist, prop.table and table
from the bnlearn package.

## Answer:

We will set score to bic and set restart to a relative big number ,say 100.
We also need to define a function to calculate the confusion matrix for the later use.

```{r q2}
###########################  Code For Exercises 2 ############################
# define a hill_climbing_prediction and use it to predict the value of S 
# and calculate the confusion matrix

# we split the data into 80% train and 20% test 
set.seed(12345)
train_index <- sample(1:nrow(asia), 0.8 * nrow(asia))
train_data <- asia[train_index, ]
test_data <- asia[-train_index, ]

# learn the BN structure 
bn_structure <- hc(train_data, score = "bic", restart = 100)

# define a function to calculate the confusion matrix
# input: test_data, training_data, hc_model, columns_index, column_nodes
hill_climbing_prediction <- function(test_data, training_data, hc_model, columns_index, column_nodes) {
  # learn the Bayesian network
  hc_fit <- bn.fit(x = hc_model, data = train_data)
  
  # convert hc_fit to a gRain object and then compile, the compiled object is used for inference
  bn_grain <- as.grain(hc_fit)
  
  # we convert the test data to a data frame, and convert all values to character
  test_data_char <- as.data.frame(lapply(test_data, as.character))
  
  bn_grain_compile <- compile(bn_grain)
 
  # define a vector to restore the prediction result
  predictions <- c()
  
  for (i in 1:nrow(test_data)) {
    
    # Create an evidence object
    # for nodes
    evidence <- setEvidence(object = bn_grain_compile, 
                            nodes = colnames(test_data)[-columns_index],
                            states = test_data_char[i,-columns_index])
    
    # query the interest node with type="marginal"
    # and we need to predict S according to the question requirement
    potentials_list <- querygrain(object = evidence, 
                                  nodes = column_nodes, 
                                  type = "marginal")$S
    
    # based on the potentials_list, we get the most likely class
    predictions[i] <- ifelse(potentials_list[1] > potentials_list[2], "no", "yes")
  }
  
  # return confusion matrix of the prediction and the true value
  confusion_matrix <- table(predictions, test_data[,column_nodes])
  
}

# predict the value based on the defined hill climbing prediction function
q2_confusion_matrix <- hill_climbing_prediction(test_data = test_data, 
                                             training_data = train_data, 
                                             hc_model = bn_structure, 
                                             columns_index = 2, 
                                             column_nodes = "S")


# true Asia BN, provided in the exercise statement.
dag <- model2network("[A][S][T|A][L|S][B|S][D|B:E][E|T:L][X|E]")

# predict the value based on true Asia BN
q2_true_confusion_matrix <- hill_climbing_prediction(test_data = test_data, 
                                                  training_data = train_data, 
                                                  hc_model = dag, 
                                                  columns_index = 2, 
                                                  column_nodes = "S")

# print the confusion matrix
cat("The confusion matrix of the hill climbing algorithm is:\n")
print(q2_confusion_matrix)
cat("The confusion matrix of the true Asia BN is:\n")
print(q2_true_confusion_matrix)
```

From the output of the 2 confusion matrices, we see two identical confusion matrices. That means the hill climbing algorithm can predict the value of S pretty well.

# Exercises 3

In the previous exercise, you classified the variable S given observations for all the
rest of the variables. Now, you are asked to classify S given observations only for the
so-called Markov blanket of S, i.e. its parents plus its children plus the parents of its
children minus S itself. Report again the confusion matrix.

Hint: You may want to use the function mb from the bnlearn package.

## Answer:

We will use the mb function to get the Markov blanket of S, and then use the Markov blanket to predict the value of S using the predefined function.

After check the confusion matrix of the Markov blanket of S and the true Asia BN output below,  we found they are same.

```{r q3}
###########################  Code For Exercises 3 ############################
# use predefined function to predict the value of S based on the Markov blanket of S
# and calculate the confusion matrix

# get the Markov blanket of S ,using the hill climbing algorithm in step 2 
markov_blanket <- mb(x = bn_structure,node = "S")

# remove the columns index of markov_blanket
markov_blanket_index <- which(!(colnames(test_data) %in% markov_blanket))
#print(markov_blanket_index)

# predict the value based on the defined hill climbing prediction function
q3_confusion_matrix <- hill_climbing_prediction(test_data = test_data, 
                                             training_data = train_data, 
                                             hc_model = bn_structure, 
                                             columns_index = markov_blanket_index, 
                                             column_nodes = "S")

# print the confusion matrix of the Markov blanket of S and true Asia BN
cat("The confusion matrix of the Markov blanket of S is:\n")
print(q3_confusion_matrix)
cat("The confusion matrix of the true Asia BN is:\n")
print(q2_true_confusion_matrix)
```

# Exercises 4

Repeat the exercise (2) using a naive Bayes classifier, i.e. the predictive variables are
independent given the class variable. See p. 380 in Bishopâ€™s book or Wikipedia for
more information on the naive Bayes classifier. Model the naive Bayes classifier as a
BN. You have to create the BN by hand, i.e. you are not allowed to use the function
naive.bayes from the bnlearn package.

Hint: Check http://www.bnlearn.com/examples/dag/ to see how to create a
BN by hand.

## Answer:

According to the definition of Naive Bayes Classifier, we found that

$$
p(C_k | x_1, x_2, ..., x_n) = p(C_k) \prod_{i=1}^{n} p(x_i | C_k)
$$
That means we define our model as following and code as below.

[S][A|S][T|S][L|S][E|S][X|S][B|S][D|S]

```{r q4}
###########################  Code For Exercises 4 ############################
# create the Naive Bayes Classifier by hand, then use predefined function to
# predict the value of S based on the Markov blanket of S and calculate the 
# confusion matrix

#dag_naive_bayes <- model2network("[S][A|S][T|S][L|S][E|S][X|S][B|S][D|S]")

# we create the BN by hand
dag_naive_bayes = empty.graph(c("A", "S", "T", "L", "B", "E", "X", "D"))

# set the arc(relations between nodes)
arc.set = matrix(c("S", "A", "S", "T", "S", "L", "S", "B", "S", "E", "S", "X", "S", "D"),
                 ncol = 2, byrow = TRUE,
                 dimnames = list(NULL, c("from", "to")))

# assign the newly created arc.set to a bn object 
arcs(dag_naive_bayes) = arc.set

# we plot the graph
graphviz.plot(dag_naive_bayes, main = "Naive Bayes Classifier")

# predict the value based on the defined hill climbing prediction function
naive_bayes_confusion_matrix <- hill_climbing_prediction(test_data = test_data, 
                                             training_data = train_data, 
                                             hc_model = dag_naive_bayes, 
                                             columns_index = 2, 
                                             column_nodes = "S")

# print the confusion matrix of naive bayes classifier and true Asia BN
cat("The confusion matrix of the Naive Bayes Classifier is:\n")
print(naive_bayes_confusion_matrix)
cat("The confusion matrix of the true Asia BN is:\n")
print(q2_true_confusion_matrix)

# calc the accuracy of the Naive Bayes Classifier and the true Asia BN
accuracy_naive_bayes <- sum(diag(naive_bayes_confusion_matrix)) / sum(naive_bayes_confusion_matrix)
accuracy_true_asia_bn <- sum(diag(q2_true_confusion_matrix)) / sum(q2_true_confusion_matrix)

cat ("The accuracy of the Naive Bayes Classifier is:", accuracy_naive_bayes, "\n")
cat ("The accuracy of the true Asia BN is:", accuracy_true_asia_bn, "\n")
```

The result below shows that the confusion matrix of the Naive Bayes Classifier is the not same as the true Asia BN. 
The accuracy of the Naive Bayes Classifier is also lower than the true Asia BN.

# Exercises 5

Explain why you obtain the same or different results in the exercises 2-4.

## Answer:

Let's check the result of exercise 2,3 and 4.

We have following 2 confusion matrices in exercise 2:

`r knitr::kable(q2_confusion_matrix,caption = "Q2 DAG Confusion Matrix")`

`r knitr::kable(q2_true_confusion_matrix,caption = "True BN Confusion Matrix")`

We have following one confusion matrix in exercise 3:

`r knitr::kable(q3_confusion_matrix,caption = "Q3 Markov Blanket Confusion Matrix")`

And we have following one confusion matrix in exercise 4:

`r knitr::kable(naive_bayes_confusion_matrix,caption = "Q4 Naive Bayes Confusion Matrix")`

And we also have the following Markov Blanket of S in different exercises.

| Name                      | Markov Blanket of S |
|---------------------------|---------------------|
| DAG (Q2)                  | L B                 |
| True BN (Q2)              | B,L                 |
| Markov Blanket (Q3)       | B,L                 |
| Naive Bayes Classifier(Q4)| A T L B E X D       |

In question 2, we find DAG and True BN have the same confusion matrix, this is because they have the same Markov Blanket of S, which is L and B.
From figure 6, we also found that left and right side of the graph are same for node S. So the result of Q2 Dag and True BN is the same.

The reason why result of question 3 is the same as the result of question 2 is because of the Markov Blanket of S. In question 2, we are asked to
calculate the posterior probability distribution of S, from the left part of Figure 5, we can find that given B and L, S is independent of other variables. In question 3, the Markov Blanket of S is B and L. So the result of question 3 is the same as the result of question 2.

For question 4, from the right side of figure 5 and the Markov blanket of S in Naive Bayes Classifier, we know that S is relies on all the children A,T,L,B,E,X,D, which is different from the (B,L) in the question 2. So the result of question 4 is different from the result of question 2 and 3.

```{r q5_plot1, fig.height=2,fig.cap="Q2 Dag vs Naive Bayes Classifier Dag", echo=FALSE}
###########################  Code For Exercises 5.1 ############################
par(mfrow = c(1, 2))
graphviz.compare(bn_structure, dag_naive_bayes)
```

```{r q5_plot2, fig.height=2,fig.cap="Q2 Dag vs True Dag", echo=FALSE}
###########################  Code For Exercises 5.1 ############################
par(mfrow = c(1, 2))
graphviz.compare(bn_structure, dag)
```

```{r q5, echo=FALSE}
# Calculate the markov blanket of S in our model, true Asia BN and Naive Bayes Classifier

# get the Markov blanket of S in our model
markov_blanket_our_model <- mb(x = bn_structure,node = "S")
# get the Markov blanket of S in true Asia BN
markov_blanket_true_asia_bn <- mb(x = dag,node = "S")
# get the Markov blanket of S in Naive Bayes Classifier
markov_blanket_naive_bayes <- mb(x = dag_naive_bayes,node = "S")

cat("The Markov blanket of S in Q2 model is:", markov_blanket_our_model, "\n")
cat("The Markov blanket of S in Q2 true Asia BN is:", markov_blanket_true_asia_bn, "\n")
cat("The Markov blanket of S in Q4 Naive Bayes Classifier is:", markov_blanket_naive_bayes, "\n")
```

\newpage
# Appendix: All code for this report

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```